from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
import PyPDF2

def read_pdf(file_path):
    with open(file_path, 'rb') as f:
        reader = PyPDF2.PdfReader(f)
        text = ""
        for page in reader.pages:
            text += page.extract_text()
    return text

def main():
    # Hugging Face eriÅŸim token'Ä±
    hf_token = "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"

    # Model bilgisi
    model_name = "csebuetnlp/mT5_multilingual_XLSum"

    # Model ve tokenizer yÃ¼kle
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, use_auth_token=hf_token)

    # Ã–zetleme pipeline'Ä±
    summarizer = pipeline("summarization", model=model, tokenizer=tokenizer)

    # ðŸ“„ PDF dosyasÄ±nÄ±n yolu
    pdf_path = "ornek.pdf"  # Kendi dosya adÄ±nla deÄŸiÅŸtir
    full_text = read_pdf(pdf_path)

    # Uzun metni parÃ§alara ayÄ±r
    chunk_size = 1000
    chunks = [full_text[i:i+chunk_size] for i in range(0, len(full_text), chunk_size)]

    all_summaries = []

    print("ðŸ“¢ Ã–zetler:")
    for i, chunk in enumerate(chunks):
        summary = summarizer(chunk, max_length=60, min_length=25, do_sample=False)[0]['summary_text']
        print(f"\nðŸ‘‰ BÃ¶lÃ¼m {i+1} Ã–zeti:\n{summary}")
        all_summaries.append(summary)

    # ðŸ”„ TÃ¼m Ã¶zetleri birleÅŸtir ve son Ã¶zetle
    combined_text = " ".join(all_summaries)
    final_summary = summarizer(combined_text, max_length=243, min_length=40, do_sample=False)[0]['summary_text']

    print("\nðŸŸ© BÄ°RLEÅžTÄ°RÄ°LMÄ°Åž TEK Ã–ZET ðŸŸ©\n")
    print(final_summary)
if __name__ == "__main__":
    main() 